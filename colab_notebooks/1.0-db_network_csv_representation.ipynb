{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "network_csv_representation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGMgIQWCbQ9C"
      },
      "source": [
        "#**Addestramento di una rete Neurale basata su LSTM per la generazione di brani musicali**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwODXD8YbuLy"
      },
      "source": [
        "#### Le seguenti sezioni sono state create al fine di rappresentare la parte principale del progetto di tesi. Essa consiste nell'addestramento di una rete neurale avendo a disposizione un dataset creato e pre-processato in precedenza in locale:\n",
        "- L' uso di librerie come **TensorFlow e Keras** sono state usate per i task di machine learning svolti;\n",
        "- L' uso della libreria **matplotlib** è stata usata per l'Analisi del modello addestrato. L'Analisi e la valutazione del modello è stato approfondito attraverso l'impiego di un altro notebook;\n",
        "- La libreria **numpy** è stata usata per la memorizzazione dell'insieme di valori di metriche per la valutazione del modello riscontrati nella parte finale dell'addestramento;\n",
        "- La libreria **pickle** è stata usata per l'estrazione dei dati dal dataset;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il8G01mSu1Bg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.optimizers import adam_v2\n",
        "\n",
        "from keras import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6rH1iTsuUXY"
      },
      "source": [
        "###Estrazione delle principali risorse usate per lo scopo:\n",
        "- modello\n",
        "- dataset \n",
        "\n",
        "*N.B. qualora ci sia il bisogno di iniziare l'addestramento dall'inizio sarà necessario estrarre solo il dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wxWR-aOu6oU",
        "outputId": "e9093429-5497-4d8e-c86e-bd886e28b5ac"
      },
      "source": [
        "!apt-get install rar\n",
        "#!unrar x \"./model.rar\" \"./\"\n",
        "#!unrar x \"./dataset_pickle.rar\" \"./\"\n",
        "#!unrar x \"./dataset_all_trasposition_minimal_pickle.rar\" \"./\"\n",
        "!unrar x \"./dataset_mini_all_trasposition_minimal_extend_pickle.rar\" \"./\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "rar is already the newest version (2:5.5.0-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from ./dataset_mini_all_trasposition_minimal_extend_pickle.rar\n",
            "\n",
            "Creating    ./dataset_mini_all_trasposition_minimal_pickle            OK\n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/durations.pickle     \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/notes.pickle     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/offsets.pickle     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/tempos.pickle     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/velocities.pickle     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/X_test.pickle     \b\b\b\b  6%\b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/X_train.pickle     \b\b\b\b 15%\b\b\b\b 20%\b\b\b\b 26%\b\b\b\b 32%\b\b\b\b 37%\b\b\b\b 43%\b\b\b\b 48%\b\b\b\b 54%\b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/X_validation.pickle     \b\b\b\b 66%\b\b\b\b 71%\b\b\b\b 77%\b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/y_test.pickle     \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/y_train.pickle     \b\b\b\b 89%\b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_mini_all_trasposition_minimal_pickle/y_validation.pickle     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQbFZONwaDsi"
      },
      "source": [
        "## Prosecuzione Training partendo da un modello salvato"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W09GaZ9aYDq"
      },
      "source": [
        "### INPUT\n",
        "\n",
        "- cartella contenente le informazioni sul modello precedentemente salvato\n",
        "- cartella contenente il dataset in formato .pickle splittato\n",
        "\n",
        "### OUTPUT\n",
        "\n",
        "- **grafici di loss e accuracy** complessiva del modello (per il numero di epoche eseguite)\n",
        "- produzione di una cartella **'model_new'** contenente il modello aggiornato\n",
        "- produzione di vari pesi con intestazione **'weights-improvement-numero_epoca-valore_di_loss_migliore-bigger.hdf5'**\n",
        "- produzione di file *.npz* contenente le varie informazioni history dell'addestramento riguardo:\n",
        "  1. **loss,accuracy e validation loss,accuracy complessiva del modello**\n",
        "  2. **loss,accuracy e validation loss,accuracy per ogni feature esaminata**\n",
        "\n",
        "*N.B. per aggiornare le risorse di input vedere ultima riga di tale blocco*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N1gqlm0u69H",
        "outputId": "11edc18e-1b46-44e3-f44a-089d4c3fdd48"
      },
      "source": [
        "def extract_sets (ROOT_PATH_DATA):\n",
        "  X_train = load_set(\"X_train.pickle\",ROOT_PATH_DATA)\n",
        "  y_train = load_set(\"y_train.pickle\",ROOT_PATH_DATA)\n",
        "  X_validation = load_set(\"X_validation.pickle\",ROOT_PATH_DATA)\n",
        "  y_validation = load_set(\"y_validation.pickle\",ROOT_PATH_DATA)\n",
        "\n",
        "  return X_train,y_train,X_validation,y_validation\n",
        "\n",
        "def load_set (name_set,path):\n",
        "  filepath1 = open(path + \"/\" + name_set, 'rb')\n",
        "  r_set = pickle.load(filepath1)\n",
        "  return r_set\n",
        "\n",
        "def evaluate_model(model,batch_size,X_test,y_test):\n",
        "  # Evaluate the model on the test data using `evaluate`\n",
        "  y_pred = model.predict(X_test, batch_size=batch_size, verbose=1)\n",
        "\n",
        "  y_pred_bool = np.argmax(np.array(y_pred[0]), axis=1)\n",
        "  y_test_bool = np.argmax(np.array(y_test[0]), axis=1)\n",
        "\n",
        "  print(\"------------------confusion matrix---------------------\")\n",
        "\n",
        "  cm = confusion_matrix(y_test_bool,y_pred_bool)\n",
        "  labels = set(y_test_bool)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "  # figsize per modificare la grandezza della matrice di confusione\n",
        "  fig, ax = plt.subplots(figsize=(35,35))\n",
        "  disp.plot(cmap=plt.cm.Blues,ax=ax)\n",
        "  plt.show()\n",
        "\n",
        "  print(\"-------------------------------------------------------\")\n",
        "\n",
        "  print(classification_report(y_test_bool, y_pred_bool))\n",
        "\n",
        "  print(\"-----------------Evaluate on test data-----------------\")\n",
        "\n",
        "  results = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "  print(\"test loss\", results[0])\n",
        "  print(\"test accuracy\", (results[4] + results[5] + results[6])/3 )\n",
        "\n",
        "  print(\"-------------------------------------------------------\")\n",
        "\n",
        "def plot_accuracy_validation(history):\n",
        "  print(history.history.keys())\n",
        "  complex_acc = [history.history['Note_acc'],history.history['Offset_acc'],history.history['Duration_acc'],history.history['Velocity_acc'],history.history['Tempo_acc']]\n",
        "  summed_acc = list(map(sum, zip(*complex_acc)))\n",
        "  \n",
        "  complex_val_acc = [history.history['val_Note_acc'],history.history['val_Offset_acc'],history.history['val_Duration_acc'],history.history['val_Velocity_acc'],history.history['val_Tempo_acc']]\n",
        "  summed_val_acc = list(map(sum, zip(*complex_val_acc)))\n",
        "  \n",
        "  n_feature = 5\n",
        "  acc = [x / n_feature for x in summed_acc]\n",
        "  val_acc = [x / n_feature for x in summed_val_acc]\n",
        "\n",
        "  save_history_element(\"accuracy_training.npz\",acc)\n",
        "  save_history_element(\"val_accuracy_training.npz\",val_acc)\n",
        "  save_history_element(\"accuracy_features.npz\",complex_acc)\n",
        "  save_history_element(\"val_accuracy_features.npz\",complex_val_acc)\n",
        "\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "def plot_loss_validation(history):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  complex_loss = [history.history['Note_loss'],history.history['Offset_loss'],history.history['Duration_loss'],history.history['Velocity_loss'],history.history['Tempo_loss']]\n",
        "  complex_val_loss = [history.history['val_Note_loss'],history.history['val_Offset_loss'],history.history['val_Duration_loss'],history.history['val_Velocity_loss'],history.history['val_Tempo_loss']]\n",
        "\n",
        "  save_history_element(\"loss_features.npz\",complex_loss)\n",
        "  save_history_element(\"val_loss_features.npz\",complex_val_loss)\n",
        "  save_history_element(\"loss_training.npz\",loss)\n",
        "  save_history_element(\"val_loss_training.npz\",val_loss)\n",
        "\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        " \n",
        "def save_history_element(filename,array):\n",
        "   np.savez_compressed(filename,array)\n",
        "\n",
        "def continue_training(ROOT_PATH_DATA,PATH_MODEL,PATH_NEW_MODEL,epochs,batch_size,verbose):\n",
        "\n",
        "  model = load_model(PATH_MODEL)\n",
        "  #model.load_weights(\"weights-improvement-15-4.5236-bigger.hdf5\")\n",
        "  model.summary()\n",
        "  X_train,y_train,X_validation,y_validation = extract_sets (ROOT_PATH_DATA)\n",
        "\n",
        "  filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor='loss',\n",
        "    verbose=verbose,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        "  )\n",
        "  callbacks_list = [checkpoint]\n",
        "  \"\"\"\n",
        "  l'addestramenta avrà:\n",
        "  - la serie di input estratte dalla parserizzazione dei file midi\n",
        "  - la serie di output corrispondenti agli input estratti nella parserizzazione (OUTPUT NON DI PREDIZIONE)\n",
        "  \"\"\"\n",
        "  #addestramento con dati di validation definiti in dati\n",
        "  history = model.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    validation_data=(X_validation,y_validation),\n",
        "    epochs = epochs, \n",
        "    batch_size = batch_size,\n",
        "    callbacks= callbacks_list\n",
        "    )\n",
        "  \n",
        "  plot_accuracy_validation(history)\n",
        "  plot_loss_validation(history)\n",
        "  model.save(PATH_NEW_MODEL)\n",
        "  \"\"\"\n",
        "  X_test = load_set(\"X_test.pickle\", ROOT_PATH_DATA)\n",
        "  y_test = load_set(\"y_test.pickle\", ROOT_PATH_DATA)\n",
        "  evaluate_model(model,batch_size,X_test,y_test)\n",
        "  \"\"\"\n",
        " \n",
        "continue_training(\"dataset_mini_all_trasposition_minimal_pickle\",\"model\",\"model_new\",15,128,0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 16, 256)      264192      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 16, 256)      264192      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 16, 256)      264192      ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 16, 256)      264192      ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  (None, 16, 256)      264192      ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 16, 256)      0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16, 256)      0           ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 16, 256)      0           ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 16, 256)      0           ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 16, 256)      0           ['lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 1280)     0           ['dropout[0][0]',                \n",
            "                                                                  'dropout_1[0][0]',              \n",
            "                                                                  'dropout_2[0][0]',              \n",
            "                                                                  'dropout_3[0][0]',              \n",
            "                                                                  'dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  (None, 16, 512)      3672064     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 16, 512)      0           ['lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_6 (LSTM)                  (None, 512)          2099200     ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512)         2048        ['lstm_6[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 512)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          131328      ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128)         512         ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128)         512         ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128)         512         ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128)         512         ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 128)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 128)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 128)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 128)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 128)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " Note (Dense)                   (None, 106)          13674       ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " Offset (Dense)                 (None, 217)          27993       ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " Duration (Dense)               (None, 174)          22446       ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " Velocity (Dense)               (None, 125)          16125       ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " Tempo (Dense)                  (None, 64)           8256        ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,481,134\n",
            "Trainable params: 7,478,830\n",
            "Non-trainable params: 2,304\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "7378/7378 [==============================] - 833s 111ms/step - loss: 4.4719 - Note_loss: 3.0169 - Offset_loss: 0.5345 - Duration_loss: 0.2233 - Velocity_loss: 0.6790 - Tempo_loss: 0.0183 - Note_acc: 0.1099 - Offset_acc: 0.8390 - Duration_acc: 0.9321 - Velocity_acc: 0.8086 - Tempo_acc: 0.9958 - val_loss: 3.8411 - val_Note_loss: 2.8354 - val_Offset_loss: 0.3618 - val_Duration_loss: 0.1348 - val_Velocity_loss: 0.5038 - val_Tempo_loss: 0.0053 - val_Note_acc: 0.1234 - val_Offset_acc: 0.8918 - val_Duration_acc: 0.9594 - val_Velocity_acc: 0.8544 - val_Tempo_acc: 0.9994\n",
            "Epoch 2/15\n",
            "7378/7378 [==============================] - 811s 110ms/step - loss: 4.4328 - Note_loss: 3.0063 - Offset_loss: 0.5227 - Duration_loss: 0.2171 - Velocity_loss: 0.6690 - Tempo_loss: 0.0177 - Note_acc: 0.1109 - Offset_acc: 0.8427 - Duration_acc: 0.9337 - Velocity_acc: 0.8109 - Tempo_acc: 0.9959 - val_loss: 3.8103 - val_Note_loss: 2.8261 - val_Offset_loss: 0.3520 - val_Duration_loss: 0.1311 - val_Velocity_loss: 0.4939 - val_Tempo_loss: 0.0071 - val_Note_acc: 0.1244 - val_Offset_acc: 0.8935 - val_Duration_acc: 0.9611 - val_Velocity_acc: 0.8573 - val_Tempo_acc: 0.9992\n",
            "Epoch 3/15\n",
            "7378/7378 [==============================] - 815s 110ms/step - loss: 4.3999 - Note_loss: 2.9974 - Offset_loss: 0.5136 - Duration_loss: 0.2110 - Velocity_loss: 0.6606 - Tempo_loss: 0.0173 - Note_acc: 0.1110 - Offset_acc: 0.8455 - Duration_acc: 0.9357 - Velocity_acc: 0.8132 - Tempo_acc: 0.9959 - val_loss: 3.7717 - val_Note_loss: 2.8127 - val_Offset_loss: 0.3437 - val_Duration_loss: 0.1273 - val_Velocity_loss: 0.4827 - val_Tempo_loss: 0.0055 - val_Note_acc: 0.1250 - val_Offset_acc: 0.8967 - val_Duration_acc: 0.9612 - val_Velocity_acc: 0.8606 - val_Tempo_acc: 0.9994\n",
            "Epoch 4/15\n",
            "4663/7378 [=================>............] - ETA: 4:20 - loss: 4.3677 - Note_loss: 2.9880 - Offset_loss: 0.5034 - Duration_loss: 0.2066 - Velocity_loss: 0.6535 - Tempo_loss: 0.0162 - Note_acc: 0.1127 - Offset_acc: 0.8489 - Duration_acc: 0.9375 - Velocity_acc: 0.8147 - Tempo_acc: 0.9962"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR-IAerJa0KN"
      },
      "source": [
        "## Addestramento con Core LSTM standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnvnb7IQa1qM"
      },
      "source": [
        "### INPUT\n",
        "\n",
        "- cartella contenente il dataset splittato composto da file in formato *.pickle*\n",
        "\n",
        "### OUTPUT\n",
        "\n",
        "- **grafici di loss e accuracy** complessiva del modello (per il numero di epoche eseguite)\n",
        "- produzione di una cartella **'model'** contenente le informazioni sul modello creato\n",
        "- produzione di vari pesi con intestazione **'weights-improvement-numero_epoca-valore_di_loss_migliore-bigger.hdf5'**\n",
        "- produzione di file *.npz* contenente le varie informazioni history dell'addestramento riguardo:\n",
        "  1. **loss,accuracy e validation loss,accuracy complessiva del modello**\n",
        "  2. **loss,accuracy e validation loss,accuracy per ogni feature esaminata**\n",
        "\n",
        "*N.B. per aggiornare le risorse di input vedere ultima riga di tale blocco*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-U6-Bv6hu7LY",
        "outputId": "dd0d7c42-3aad-441b-ab4d-9c567d399d14"
      },
      "source": [
        "def train_network(\n",
        "  ROOT_PATH_DATA,PATH_MODEL,\n",
        "  epochs,batch_size,verbose\n",
        "  ):\n",
        "    print (\"read dataset...\")\n",
        "    X_train = load_set(\"X_train.pickle\",ROOT_PATH_DATA)\n",
        "    y_train = load_set(\"y_train.pickle\",ROOT_PATH_DATA)\n",
        "    X_validation = load_set(\"X_validation.pickle\",ROOT_PATH_DATA)\n",
        "    y_validation = load_set(\"y_validation.pickle\",ROOT_PATH_DATA)\n",
        "    #X_test = load_set(\"X_test.pickle\",ROOT_PATH_DATA)\n",
        "    #y_test = load_set(\"y_test.pickle\",ROOT_PATH_DATA)\n",
        "    X_test = []\n",
        "    y_test = []    \n",
        "    print(\"create network skeleton\")\n",
        "    \n",
        "    model = create_network(\n",
        "        X_train[0],y_train[0].shape[1],\n",
        "        X_train[1], y_train[1].shape[1],\n",
        "        X_train[2], y_train[2].shape[1],\n",
        "        X_train[3], y_train[3].shape[1],\n",
        "        X_train[4], y_train[4].shape[1]\n",
        "    )\n",
        "\n",
        "    print(\"prepare training...\")\n",
        "    \n",
        "    \n",
        "    train_with_validation_data(\n",
        "        model,\n",
        "        X_train,y_train,\n",
        "        X_validation,y_validation,\n",
        "        X_test,y_test,\n",
        "        PATH_MODEL,epochs,batch_size,verbose\n",
        "    )\n",
        "  \n",
        "    \n",
        "def network_branch_to_consider(network_input):\n",
        "  \"\"\"\n",
        "  si distinguono due tipologie di input (che sono output di tale funzione):\n",
        "  inputin --> ESSI COSTITUISCONO IL NODO DI INPUT DELLA RETE NEURALE E NON PER LA COSTRUZIONE DEL MODELLO\n",
        "  inputLayer -->  input utili alla costruzione del modello Model (DEFINIZIONE DELLO SPAZIO RISERVATO ALL'INPUT)\n",
        "  \"\"\"\n",
        "  inputLayer = Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
        "  inputin = LSTM(\n",
        "    256,\n",
        "    input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "    return_sequences=True\n",
        "  )(inputLayer)\n",
        "  inputin = Dropout(0.5)(inputin)\n",
        "\n",
        "  return inputin,inputLayer\n",
        "\n",
        "def network_branch_to_classify(string_desc,result_RNN,n_vocab):\n",
        "  \"\"\"\n",
        "  il risultato di tale funzione COSTITUISCE IL NODO DI OUTPUT DELLA RETE NEURALE\n",
        "  \"\"\"\n",
        "  output = Dense(128, activation='relu')(result_RNN)\n",
        "  output = BatchNorm()(output)\n",
        "  output = Dropout(0.5)(output)\n",
        "  output = Dense(n_vocab, activation='softmax', name=string_desc)(output)\n",
        "  return output\n",
        "\n",
        "def create_network(\n",
        "    network_input_notes,n_vocab_notes,\n",
        "    network_input_offsets, n_vocab_offsets,\n",
        "    network_input_durations, n_vocab_durations,\n",
        "    network_input_velocities, n_vocab_velocities,\n",
        "    network_input_tempos, n_vocab_tempos\n",
        "    ):\n",
        "  \"\"\"\n",
        "  in tale funzione network_input_notes,network_input_offsets,network_input_durations sono usati\n",
        "  ESCLUSIVAMENTE NON PER IL LORO CONTENUTO MA PER LE LORO DIMENSIONI O SHAPE\n",
        "  \"\"\"\n",
        "\n",
        "  #costruzione dei due differenti input\n",
        "  inputNotes,inputNotesLayer = network_branch_to_consider(network_input_notes)\n",
        "  inputOffsets,inputOffsetsLayer = network_branch_to_consider(network_input_offsets)\n",
        "  inputDurations,inputDurationsLayer = network_branch_to_consider(network_input_durations)\n",
        "  inputVelocities,inputVelocitiesLayer = network_branch_to_consider(network_input_velocities)\n",
        "  inputTempos,inputTemposLayer = network_branch_to_consider(network_input_tempos)\n",
        "\n",
        "  # concatenazione degli input da dare in pasto alla rete neurale GRU\n",
        "  inputs = concatenate([inputNotes, inputOffsets, inputDurations,inputVelocities,inputTempos])\n",
        "\n",
        "  # costruzione della GRU proposta nel documento per considerare cosa ha imparato nei tre differenti Branches\n",
        "\n",
        "  x = LSTM(512, return_sequences=True)(inputs)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = LSTM(512)(x)\n",
        "  x = BatchNorm()(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(256, activation='relu')(x)\n",
        "\n",
        "  outputNotes = network_branch_to_classify(\"Note\",x,n_vocab_notes)\n",
        "  outputOffsets = network_branch_to_classify(\"Offset\",x,n_vocab_offsets)\n",
        "  outputDurations = network_branch_to_classify(\"Duration\",x,n_vocab_durations)\n",
        "  outputVelocities = network_branch_to_classify(\"Velocity\",x,n_vocab_velocities)\n",
        "  outputTempos = network_branch_to_classify(\"Tempo\",x,n_vocab_tempos)\n",
        "\n",
        "  model = Model(\n",
        "    inputs=[inputNotesLayer, inputOffsetsLayer, inputDurationsLayer,inputVelocitiesLayer,inputTemposLayer], \n",
        "    outputs=[outputNotes, outputOffsets, outputDurations,outputVelocities,outputTempos]\n",
        "  )\n",
        "\n",
        "  #compilazione del modello\n",
        "  model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics= ['acc'],\n",
        "    optimizer='adam'\n",
        "  )\n",
        "  # Useful to try RMSProp though\n",
        "  #model.compile(loss='categorical_crossentropy', optimizer= \"RMSprop\")\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_with_validation_data(\n",
        "\tmodel, \n",
        "\tX_train,y_train,\n",
        "\tX_val,y_val,\n",
        "  X_test,y_test,\n",
        "\tPATH_MODEL,epochs,batch_size,verbose):\n",
        "\t\n",
        "  \"\"\"\n",
        "  in tale funzione di training i dati di input e di output vengono immessi \n",
        "  ESCLUSIVAMENTE CONSIDERANDO IL LORO CONTENUTO\n",
        "  \"\"\"\n",
        "  filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "\n",
        "  checkpoint_loss = ModelCheckpoint(\n",
        "    filepath,\n",
        "    period = 10,\n",
        "    monitor='loss',\n",
        "    verbose=verbose,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        "  )\n",
        "\n",
        "  callbacks_list = [checkpoint_loss]\n",
        "  \"\"\"\n",
        "  l'addestramenta avrà:\n",
        "  - la serie di input estratte dalla parserizzazione dei file midi\n",
        "  - la serie di output corrispondenti agli input estratti nella parserizzazione (OUTPUT NON DI PREDIZIONE)\n",
        "  \"\"\"\n",
        "  #addestramento con dati di validation definiti in dati\n",
        "  history = model.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    validation_data=(X_val,y_val),\n",
        "    epochs = epochs, \n",
        "    batch_size = batch_size,\n",
        "    callbacks= callbacks_list\n",
        "    )\n",
        "  #evaluate_model(model,batch_size,X_test,y_test)\n",
        "  plot_accuracy_validation(history)\n",
        "  plot_loss_validation(history)\n",
        "\n",
        "  model.save(PATH_MODEL)\n",
        "\n",
        "def plot_accuracy_validation(history):\n",
        "  print(history.history.keys())\n",
        "  complex_acc = [history.history['Note_acc'],history.history['Offset_acc'],history.history['Duration_acc'],history.history['Velocity_acc'],history.history['Tempo_acc']]\n",
        "  summed_acc = list(map(sum, zip(*complex_acc)))\n",
        "  \n",
        "  complex_val_acc = [history.history['val_Note_acc'],history.history['val_Offset_acc'],history.history['val_Duration_acc'],history.history['val_Velocity_acc'],history.history['val_Tempo_acc']]\n",
        "  summed_val_acc = list(map(sum, zip(*complex_val_acc)))\n",
        "  \n",
        "  n_feature = 5\n",
        "  acc = [x / n_feature for x in summed_acc]\n",
        "  val_acc = [x / n_feature for x in summed_val_acc]\n",
        "\n",
        "  save_history_element(\"accuracy_features.npz\",complex_acc)\n",
        "  save_history_element(\"val_accuracy_features.npz\",complex_val_acc)\n",
        "\n",
        "  save_history_element(\"accuracy_training.npz\",acc)\n",
        "  save_history_element(\"val_accuracy_training.npz\",val_acc)\n",
        "\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "def plot_loss_validation(history):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  complex_loss = [history.history[\"Note_loss\"],history.history[\"Offset_loss\"],history.history[\"Duration_loss\"],history.history[\"Velocity_loss\"],history.history[\"Tempo_loss\"]]\n",
        "  complex_val_loss = [history.history[\"val_Note_loss\"],history.history[\"val_Offset_loss\"],history.history[\"val_Duration_loss\"],history.history[\"val_Velocity_loss\"],history.history[\"val_Tempo_loss\"]]\n",
        "\n",
        "  save_history_element(\"loss_features.npz\",complex_loss)\n",
        "  save_history_element(\"val_loss_features.npz\",complex_val_loss)\n",
        "\n",
        "  save_history_element(\"loss_training.npz\",loss)\n",
        "  save_history_element(\"val_loss_training.npz\",val_loss)\n",
        "\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "def load_set (name_set,path):\n",
        "    filepath1 = open(path + \"/\" + name_set, 'rb')\n",
        "    r_set = pickle.load(filepath1)\n",
        "    return r_set\n",
        "\n",
        "def save_history_element(filename,array):\n",
        "   np.savez_compressed(filename,array)\n",
        "\n",
        "train_network(\n",
        "    \"dataset_mini_all_trasposition_minimal_pickle\",\"model\",\n",
        "\t  15,128,0\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read dataset...\n",
            "create network skeleton\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 16, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 16, 256)      264192      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 16, 256)      264192      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 16, 256)      264192      ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 16, 256)      264192      ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  (None, 16, 256)      264192      ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 16, 256)      0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16, 256)      0           ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 16, 256)      0           ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 16, 256)      0           ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 16, 256)      0           ['lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 1280)     0           ['dropout[0][0]',                \n",
            "                                                                  'dropout_1[0][0]',              \n",
            "                                                                  'dropout_2[0][0]',              \n",
            "                                                                  'dropout_3[0][0]',              \n",
            "                                                                  'dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  (None, 16, 512)      3672064     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 16, 512)      0           ['lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_6 (LSTM)                  (None, 512)          2099200     ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512)         2048        ['lstm_6[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 512)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          131328      ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128)         512         ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128)         512         ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128)         512         ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128)         512         ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 128)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 128)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 128)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 128)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 128)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " Note (Dense)                   (None, 103)          13287       ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " Offset (Dense)                 (None, 217)          27993       ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " Duration (Dense)               (None, 174)          22446       ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " Velocity (Dense)               (None, 125)          16125       ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " Tempo (Dense)                  (None, 64)           8256        ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,480,747\n",
            "Trainable params: 7,478,443\n",
            "Non-trainable params: 2,304\n",
            "__________________________________________________________________________________________________\n",
            "prepare training...\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "3826/3826 [==============================] - 443s 111ms/step - loss: 9.3814 - Note_loss: 3.8739 - Offset_loss: 1.8083 - Duration_loss: 1.2682 - Velocity_loss: 1.7749 - Tempo_loss: 0.6561 - Note_acc: 0.0519 - Offset_acc: 0.4733 - Duration_acc: 0.5960 - Velocity_acc: 0.6041 - Tempo_acc: 0.7991 - val_loss: 7.4664 - val_Note_loss: 3.6451 - val_Offset_loss: 1.4013 - val_Duration_loss: 1.0057 - val_Velocity_loss: 1.3002 - val_Tempo_loss: 0.1141 - val_Note_acc: 0.0670 - val_Offset_acc: 0.5548 - val_Duration_acc: 0.6303 - val_Velocity_acc: 0.6657 - val_Tempo_acc: 0.9661\n",
            "Epoch 2/15\n",
            "3826/3826 [==============================] - 420s 110ms/step - loss: 7.4755 - Note_loss: 3.6443 - Offset_loss: 1.4063 - Duration_loss: 0.9574 - Velocity_loss: 1.3117 - Tempo_loss: 0.1559 - Note_acc: 0.0651 - Offset_acc: 0.5593 - Duration_acc: 0.6541 - Velocity_acc: 0.6708 - Tempo_acc: 0.9526 - val_loss: 6.5857 - val_Note_loss: 3.4880 - val_Offset_loss: 1.2015 - val_Duration_loss: 0.7669 - val_Velocity_loss: 1.0897 - val_Tempo_loss: 0.0396 - val_Note_acc: 0.0815 - val_Offset_acc: 0.6107 - val_Duration_acc: 0.7208 - val_Velocity_acc: 0.7110 - val_Tempo_acc: 0.9896\n",
            "Epoch 3/15\n",
            "3826/3826 [==============================] - 420s 110ms/step - loss: 6.7589 - Note_loss: 3.5088 - Offset_loss: 1.2437 - Duration_loss: 0.7584 - Velocity_loss: 1.1601 - Tempo_loss: 0.0880 - Note_acc: 0.0782 - Offset_acc: 0.6113 - Duration_acc: 0.7349 - Velocity_acc: 0.7027 - Tempo_acc: 0.9755 - val_loss: 5.9741 - val_Note_loss: 3.3149 - val_Offset_loss: 1.0352 - val_Duration_loss: 0.5985 - val_Velocity_loss: 0.9814 - val_Tempo_loss: 0.0442 - val_Note_acc: 0.0974 - val_Offset_acc: 0.6719 - val_Duration_acc: 0.7906 - val_Velocity_acc: 0.7332 - val_Tempo_acc: 0.9869\n",
            "Epoch 4/15\n",
            "3826/3826 [==============================] - 421s 110ms/step - loss: 6.2611 - Note_loss: 3.3833 - Offset_loss: 1.1061 - Duration_loss: 0.6396 - Velocity_loss: 1.0717 - Tempo_loss: 0.0605 - Note_acc: 0.0905 - Offset_acc: 0.6576 - Duration_acc: 0.7805 - Velocity_acc: 0.7204 - Tempo_acc: 0.9846 - val_loss: 5.5991 - val_Note_loss: 3.1933 - val_Offset_loss: 0.9179 - val_Duration_loss: 0.5112 - val_Velocity_loss: 0.9108 - val_Tempo_loss: 0.0659 - val_Note_acc: 0.1090 - val_Offset_acc: 0.7127 - val_Duration_acc: 0.8231 - val_Velocity_acc: 0.7496 - val_Tempo_acc: 0.9811\n",
            "Epoch 5/15\n",
            "3826/3826 [==============================] - 422s 110ms/step - loss: 5.9137 - Note_loss: 3.2884 - Offset_loss: 1.0067 - Duration_loss: 0.5588 - Velocity_loss: 1.0124 - Tempo_loss: 0.0474 - Note_acc: 0.1000 - Offset_acc: 0.6906 - Duration_acc: 0.8109 - Velocity_acc: 0.7323 - Tempo_acc: 0.9883 - val_loss: 5.2001 - val_Note_loss: 3.0848 - val_Offset_loss: 0.8208 - val_Duration_loss: 0.4327 - val_Velocity_loss: 0.8498 - val_Tempo_loss: 0.0121 - val_Note_acc: 0.1200 - val_Offset_acc: 0.7427 - val_Duration_acc: 0.8530 - val_Velocity_acc: 0.7629 - val_Tempo_acc: 0.9979\n",
            "Epoch 6/15\n",
            "3826/3826 [==============================] - 422s 110ms/step - loss: 5.6595 - Note_loss: 3.2159 - Offset_loss: 0.9347 - Duration_loss: 0.5016 - Velocity_loss: 0.9679 - Tempo_loss: 0.0395 - Note_acc: 0.1079 - Offset_acc: 0.7139 - Duration_acc: 0.8326 - Velocity_acc: 0.7418 - Tempo_acc: 0.9904 - val_loss: 4.9652 - val_Note_loss: 3.0100 - val_Offset_loss: 0.7522 - val_Duration_loss: 0.3839 - val_Velocity_loss: 0.8086 - val_Tempo_loss: 0.0105 - val_Note_acc: 0.1297 - val_Offset_acc: 0.7672 - val_Duration_acc: 0.8716 - val_Velocity_acc: 0.7748 - val_Tempo_acc: 0.9983\n",
            "Epoch 7/15\n",
            "3826/3826 [==============================] - 422s 110ms/step - loss: 5.4586 - Note_loss: 3.1589 - Offset_loss: 0.8789 - Duration_loss: 0.4548 - Velocity_loss: 0.9321 - Tempo_loss: 0.0338 - Note_acc: 0.1141 - Offset_acc: 0.7321 - Duration_acc: 0.8494 - Velocity_acc: 0.7489 - Tempo_acc: 0.9919 - val_loss: 4.7905 - val_Note_loss: 2.9528 - val_Offset_loss: 0.7036 - val_Duration_loss: 0.3451 - val_Velocity_loss: 0.7778 - val_Tempo_loss: 0.0112 - val_Note_acc: 0.1346 - val_Offset_acc: 0.7817 - val_Duration_acc: 0.8872 - val_Velocity_acc: 0.7793 - val_Tempo_acc: 0.9979\n",
            "Epoch 8/15\n",
            "3826/3826 [==============================] - 423s 111ms/step - loss: 5.3080 - Note_loss: 3.1125 - Offset_loss: 0.8358 - Duration_loss: 0.4220 - Velocity_loss: 0.9064 - Tempo_loss: 0.0312 - Note_acc: 0.1184 - Offset_acc: 0.7460 - Duration_acc: 0.8620 - Velocity_acc: 0.7541 - Tempo_acc: 0.9927 - val_loss: 4.6517 - val_Note_loss: 2.9089 - val_Offset_loss: 0.6662 - val_Duration_loss: 0.3200 - val_Velocity_loss: 0.7488 - val_Tempo_loss: 0.0076 - val_Note_acc: 0.1397 - val_Offset_acc: 0.7947 - val_Duration_acc: 0.8971 - val_Velocity_acc: 0.7882 - val_Tempo_acc: 0.9990\n",
            "Epoch 9/15\n",
            "3826/3826 [==============================] - 422s 110ms/step - loss: 5.1709 - Note_loss: 3.0698 - Offset_loss: 0.7975 - Duration_loss: 0.3931 - Velocity_loss: 0.8812 - Tempo_loss: 0.0293 - Note_acc: 0.1224 - Offset_acc: 0.7574 - Duration_acc: 0.8722 - Velocity_acc: 0.7599 - Tempo_acc: 0.9931 - val_loss: 4.5322 - val_Note_loss: 2.8658 - val_Offset_loss: 0.6354 - val_Duration_loss: 0.2963 - val_Velocity_loss: 0.7262 - val_Tempo_loss: 0.0085 - val_Note_acc: 0.1448 - val_Offset_acc: 0.8041 - val_Duration_acc: 0.9049 - val_Velocity_acc: 0.7944 - val_Tempo_acc: 0.9988\n",
            "Epoch 10/15\n",
            "3826/3826 [==============================] - 449s 117ms/step - loss: 5.0653 - Note_loss: 3.0365 - Offset_loss: 0.7692 - Duration_loss: 0.3717 - Velocity_loss: 0.8595 - Tempo_loss: 0.0284 - Note_acc: 0.1270 - Offset_acc: 0.7658 - Duration_acc: 0.8800 - Velocity_acc: 0.7647 - Tempo_acc: 0.9933 - val_loss: 4.4446 - val_Note_loss: 2.8351 - val_Offset_loss: 0.6099 - val_Duration_loss: 0.2816 - val_Velocity_loss: 0.7093 - val_Tempo_loss: 0.0086 - val_Note_acc: 0.1489 - val_Offset_acc: 0.8121 - val_Duration_acc: 0.9108 - val_Velocity_acc: 0.7973 - val_Tempo_acc: 0.9986\n",
            "Epoch 11/15\n",
            "3826/3826 [==============================] - 449s 117ms/step - loss: 4.9788 - Note_loss: 3.0077 - Offset_loss: 0.7450 - Duration_loss: 0.3531 - Velocity_loss: 0.8479 - Tempo_loss: 0.0251 - Note_acc: 0.1310 - Offset_acc: 0.7732 - Duration_acc: 0.8867 - Velocity_acc: 0.7674 - Tempo_acc: 0.9940 - val_loss: 4.3455 - val_Note_loss: 2.7995 - val_Offset_loss: 0.5828 - val_Duration_loss: 0.2612 - val_Velocity_loss: 0.6924 - val_Tempo_loss: 0.0096 - val_Note_acc: 0.1540 - val_Offset_acc: 0.8215 - val_Duration_acc: 0.9181 - val_Velocity_acc: 0.8021 - val_Tempo_acc: 0.9985\n",
            "Epoch 12/15\n",
            "3826/3826 [==============================] - 425s 111ms/step - loss: 4.8873 - Note_loss: 2.9776 - Offset_loss: 0.7203 - Duration_loss: 0.3357 - Velocity_loss: 0.8279 - Tempo_loss: 0.0257 - Note_acc: 0.1347 - Offset_acc: 0.7809 - Duration_acc: 0.8926 - Velocity_acc: 0.7719 - Tempo_acc: 0.9940 - val_loss: 4.2747 - val_Note_loss: 2.7739 - val_Offset_loss: 0.5631 - val_Duration_loss: 0.2514 - val_Velocity_loss: 0.6781 - val_Tempo_loss: 0.0082 - val_Note_acc: 0.1566 - val_Offset_acc: 0.8279 - val_Duration_acc: 0.9215 - val_Velocity_acc: 0.8074 - val_Tempo_acc: 0.9990\n",
            "Epoch 13/15\n",
            "3826/3826 [==============================] - 425s 111ms/step - loss: 4.8184 - Note_loss: 2.9546 - Offset_loss: 0.7011 - Duration_loss: 0.3230 - Velocity_loss: 0.8149 - Tempo_loss: 0.0247 - Note_acc: 0.1383 - Offset_acc: 0.7872 - Duration_acc: 0.8982 - Velocity_acc: 0.7749 - Tempo_acc: 0.9941 - val_loss: 4.2006 - val_Note_loss: 2.7438 - val_Offset_loss: 0.5448 - val_Duration_loss: 0.2408 - val_Velocity_loss: 0.6624 - val_Tempo_loss: 0.0088 - val_Note_acc: 0.1627 - val_Offset_acc: 0.8311 - val_Duration_acc: 0.9241 - val_Velocity_acc: 0.8111 - val_Tempo_acc: 0.9988\n",
            "Epoch 14/15\n",
            "3826/3826 [==============================] - 425s 111ms/step - loss: 4.7485 - Note_loss: 2.9285 - Offset_loss: 0.6825 - Duration_loss: 0.3107 - Velocity_loss: 0.8030 - Tempo_loss: 0.0237 - Note_acc: 0.1429 - Offset_acc: 0.7925 - Duration_acc: 0.9020 - Velocity_acc: 0.7781 - Tempo_acc: 0.9945 - val_loss: 4.1391 - val_Note_loss: 2.7176 - val_Offset_loss: 0.5324 - val_Duration_loss: 0.2299 - val_Velocity_loss: 0.6523 - val_Tempo_loss: 0.0070 - val_Note_acc: 0.1684 - val_Offset_acc: 0.8369 - val_Duration_acc: 0.9284 - val_Velocity_acc: 0.8135 - val_Tempo_acc: 0.9992\n",
            "Epoch 15/15\n",
            "3826/3826 [==============================] - 426s 111ms/step - loss: 4.6891 - Note_loss: 2.9040 - Offset_loss: 0.6694 - Duration_loss: 0.3019 - Velocity_loss: 0.7907 - Tempo_loss: 0.0231 - Note_acc: 0.1475 - Offset_acc: 0.7967 - Duration_acc: 0.9047 - Velocity_acc: 0.7806 - Tempo_acc: 0.9944 - val_loss: 4.0835 - val_Note_loss: 2.6911 - val_Offset_loss: 0.5173 - val_Duration_loss: 0.2261 - val_Velocity_loss: 0.6410 - val_Tempo_loss: 0.0080 - val_Note_acc: 0.1792 - val_Offset_acc: 0.8420 - val_Duration_acc: 0.9304 - val_Velocity_acc: 0.8167 - val_Tempo_acc: 0.9991\n",
            "dict_keys(['loss', 'Note_loss', 'Offset_loss', 'Duration_loss', 'Velocity_loss', 'Tempo_loss', 'Note_acc', 'Offset_acc', 'Duration_acc', 'Velocity_acc', 'Tempo_acc', 'val_loss', 'val_Note_loss', 'val_Offset_loss', 'val_Duration_loss', 'val_Velocity_loss', 'val_Tempo_loss', 'val_Note_acc', 'val_Offset_acc', 'val_Duration_acc', 'val_Velocity_acc', 'val_Tempo_acc'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4df3bb6550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4df00c8290> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4d7c3c03d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4d7c28c3d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4d7c2c2d50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4d7c1bbc10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4d7c1f4050> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    }
  ]
}