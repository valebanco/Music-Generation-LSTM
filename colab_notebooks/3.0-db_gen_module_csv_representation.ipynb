{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gen_module_csv_representation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Vxw1IprCmy"
      },
      "source": [
        "# Modulo di generazione di brani a partire da un modello salvato"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6W9P7-9rO3O"
      },
      "source": [
        "Le sezioni che seguiranno sono state realizzate con l'obbiettivo di generare un set di brani in formato .mid in tracce di piano forte."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul6aW3JQOg-1"
      },
      "source": [
        "import pickle\n",
        "import numpy\n",
        "import keras\n",
        "from music21 import instrument, note, stream, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import GRU\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.layers import Activation\n",
        "\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Input\n",
        "from tensorflow.python.framework.importer import import_graph_def\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swnXIwoXt-JG"
      },
      "source": [
        "###Estrazione delle principali risorse usate per lo scopo:\n",
        "- modello\n",
        "- dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEiW-6v6Oupb",
        "outputId": "ceeb0d58-473b-4a1b-b3d8-a3fe751bbe92"
      },
      "source": [
        "!apt-get install rar\n",
        "!unrar x \"d_prova_pickle.rar\" \"./\"\n",
        "#!unrar x \"dataset_pickle.rar\" \"./\"\n",
        "!unrar x \"./model.rar\" \"./\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  rar\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 295 kB of archives.\n",
            "After this operation, 799 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 rar amd64 2:5.5.0-1 [295 kB]\n",
            "Fetched 295 kB in 0s (3,837 kB/s)\n",
            "Selecting previously unselected package rar.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../rar_2%3a5.5.0-1_amd64.deb ...\n",
            "Unpacking rar (2:5.5.0-1) ...\n",
            "Setting up rar (2:5.5.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from dataset_pickle.rar\n",
            "\n",
            "Creating    ./dataset_pickle                                          OK\n",
            "Creating    ./dataset_pickle/dataset_pickle                           OK\n",
            "Extracting  ./dataset_pickle/dataset_pickle/durations.pickle             \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/notes.pickle                 \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/offsets.pickle               \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/tempos.pickle                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/velocities.pickle            \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/X_test.pickle                \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/X_train.pickle               \b\b\b\b 18%\b\b\b\b 27%\b\b\b\b 35%\b\b\b\b 44%\b\b\b\b 52%\b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/X_validation.pickle          \b\b\b\b 69%\b\b\b\b 78%\b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/y_test.pickle                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/y_train.pickle               \b\b\b\b 93%\b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  ./dataset_pickle/dataset_pickle/y_validation.pickle          \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from ./model.rar\n",
            "\n",
            "Creating    ./model                                                   OK\n",
            "Extracting  ./model/keras_metadata.pb                                    \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  ./model/saved_model.pb                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Creating    ./model/variables                                         OK\n",
            "Extracting  ./model/variables/variables.data-00000-of-00001              \b\b\b\b  5%\b\b\b\b 10%\b\b\b\b 15%\b\b\b\b 20%\b\b\b\b 25%\b\b\b\b 30%\b\b\b\b 35%\b\b\b\b 40%\b\b\b\b 45%\b\b\b\b 50%\b\b\b\b 55%\b\b\b\b 60%\b\b\b\b 65%\b\b\b\b 70%\b\b\b\b 75%\b\b\b\b 80%\b\b\b\b 85%\b\b\b\b 90%\b\b\b\b 95%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  ./model/variables/variables.index                            \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePmVnSQur2NH"
      },
      "source": [
        "###INPUT\n",
        "\n",
        "- riferimento alla cartella del dataset in formato pickle\n",
        "- riferimento alla cartella contenente le informazioni del modello\n",
        "- opzionalmente è possibile immettere i pesi ottimali del modello\n",
        "\n",
        "### OUTPUT\n",
        "\n",
        "- fornitura di un set di file in formato csv da convertire in midi e successivamente in mp3 allo scopo di effettuare un ascolto soggettivo del brano/i generato/i."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZojDxnoOxay"
      },
      "source": [
        "def load_test_sequences(ROOT_PATH_DATA):\n",
        "  filepath_X_test = open(ROOT_PATH_DATA + \"/X_validation.pickle\",'rb')\n",
        "  test_sequences = pickle.load(filepath_X_test)\n",
        "\n",
        "  network_input_notes = test_sequences[0]\n",
        "  network_input_offsets = test_sequences[1]\n",
        "  network_input_durations = test_sequences[2] \n",
        "  network_input_velocities = test_sequences[3]\n",
        "  network_input_tempos = test_sequences[4] \n",
        "\n",
        "  return network_input_notes,network_input_offsets,network_input_durations,network_input_velocities,network_input_tempos\n",
        "\n",
        "def load_features(ROOT_PATH_DATA):\n",
        "\n",
        "  filepath_notes = open(ROOT_PATH_DATA + \"/notes.pickle\",'rb')\n",
        "  notes = pickle.load(filepath_notes)\n",
        "\n",
        "  filepath_offsets = open(ROOT_PATH_DATA + \"/offsets.pickle\",'rb')\n",
        "  offsets = pickle.load(filepath_offsets)\n",
        "\n",
        "  filepath_durations = open(ROOT_PATH_DATA + \"/durations.pickle\",'rb')\n",
        "  durations = pickle.load(filepath_durations)\n",
        "\n",
        "  filepath_velocities = open(ROOT_PATH_DATA + \"/velocities.pickle\",'rb')\n",
        "  velocities = pickle.load(filepath_velocities)\n",
        "\n",
        "  filepath_tempos = open(ROOT_PATH_DATA + \"/tempos.pickle\",'rb')\n",
        "  tempos = pickle.load(filepath_tempos)\n",
        "\n",
        "  return notes,offsets,durations,velocities,tempos\n",
        "\n",
        "def load_model_from_local(PATH_MODEL):\n",
        "  model = keras.models.load_model(PATH_MODEL)\n",
        "  return model\n",
        "\n",
        "def generate_music(\n",
        "model, \n",
        "network_input_notes,network_input_offsets,network_input_durations,network_input_velocities,network_input_tempos,\n",
        "notenames, offsetnames, durationames,velocitynames, temponames,\n",
        "n_vocab_notes, n_vocab_offsets, n_vocab_durations,n_vocab_velocities,n_vocab_tempos\n",
        "):\n",
        "\n",
        "  \"\"\" Generazione di note dalla rete neurale su una sequenza di note \"\"\"\n",
        "\n",
        "  # stabilimento di una sequenza casuale dall'input come punto di partenza per la predizione\n",
        "  start = numpy.random.randint(0, len(network_input_notes)-1)\n",
        "\n",
        "  # creo un dizionario dei dati nella quale ogni elemento che sia nota che offset che durata sia identificato come una coppia(chiave,valore)\n",
        "  int_to_note = dict((number, note) for number, note in enumerate(notenames))\n",
        "  int_to_offset = dict((number, offset) for number, offset in enumerate(offsetnames))\n",
        "  int_to_duration = dict((number, duration) for number, duration in enumerate(durationames))\n",
        "  int_to_velocity = dict((number, velocity) for number,velocity  in enumerate(velocitynames))\n",
        "  int_to_tempo = dict((number, tempo) for number,tempo in enumerate(temponames))\n",
        "\n",
        "  # inizio la formulazione dei pattern indicando uno degli elementi per ogni lista\n",
        "  pattern = network_input_notes[start].flatten().tolist()\n",
        "  pattern2 = network_input_offsets[start].flatten().tolist()\n",
        "  pattern3 = network_input_durations[start].flatten().tolist()\n",
        "  pattern4 = network_input_velocities[start].flatten().tolist()\n",
        "  pattern5 = network_input_tempos[start].flatten().tolist()\n",
        "\n",
        "\n",
        "  prediction_output = []\n",
        "\n",
        "  # generazione di note o accordi\n",
        "  for i in range(300):\n",
        "    sequence_lenght = len(pattern)\n",
        "\n",
        "    note_prediction_input = numpy.reshape(pattern, (1, sequence_lenght, 1))\n",
        "    predictedNote = note_prediction_input[-1][-1][-1]\n",
        "\n",
        "    offset_prediction_input = numpy.reshape(pattern2, (1, sequence_lenght, 1))\n",
        "\n",
        "    duration_prediction_input = numpy.reshape(pattern3, (1, sequence_lenght, 1))\n",
        "\n",
        "    tempo_prediction_input = numpy.reshape(pattern5, (1, sequence_lenght, 1))\n",
        "\n",
        "    velocity_prediction_input = numpy.reshape(pattern4, (1, sequence_lenght, 1))\n",
        "\n",
        "    input_prediction = [note_prediction_input, offset_prediction_input, duration_prediction_input,velocity_prediction_input,tempo_prediction_input]\n",
        "\n",
        "    #print(note_prediction_input)\n",
        "    #predizione di note, offset e durate\n",
        "    prediction = model.predict(input_prediction, verbose=0)\n",
        "\n",
        "    \"\"\"\n",
        "    estraggo le feature predette con:\n",
        "    - argmax --> funzione che restituisce l'indice dell'elemento massimo (probabilità massima) \n",
        "      all'interno del vettore di probabilità fornito dalla funzione predict\n",
        "    \"\"\"\n",
        "\n",
        "    note_index = numpy.argmax(prediction[0])\n",
        "    note_result = int_to_note[note_index]\n",
        "\n",
        "    offset = numpy.argmax(prediction[2])\n",
        "    offset_result = int_to_offset[offset]\n",
        "\n",
        "    duration = numpy.argmax(prediction[1])\n",
        "    duration_result = int_to_duration[duration]\n",
        "\n",
        "    velocity = numpy.argmax(prediction[3])\n",
        "    velocity_result = int_to_velocity[velocity]\n",
        "\n",
        "    tempo = numpy.argmax(prediction[4])\n",
        "    tempo_result = int_to_tempo[tempo]\n",
        "\n",
        "    # stampo le feature predette\n",
        "    print(\"Next note: \" + str(int_to_note[note_index]) \n",
        "    + \" - Duration: \" + str(int_to_duration[duration]) \n",
        "    + \" - Offset: \" + str(int_to_offset[offset])\n",
        "    + \" - velocity: \" + str(int_to_velocity[velocity]) \n",
        "    + \" - tempo: \" + str(int_to_tempo[tempo]))\n",
        "\n",
        "    prediction_output.append([note_result, offset_result, duration_result,velocity_result,tempo_result])\n",
        "\n",
        "    pattern.append(note_index/n_vocab_notes)\n",
        "    pattern2.append(offset/n_vocab_offsets)\n",
        "    pattern3.append(duration/n_vocab_durations)\n",
        "    pattern4.append(offset/n_vocab_offsets)\n",
        "    pattern5.append(duration/n_vocab_durations)\n",
        "    \n",
        "    pattern = pattern[1:len(pattern)]\n",
        "    pattern2 = pattern2[1:len(pattern2)]\n",
        "    pattern3 = pattern3[1:len(pattern3)]\n",
        "    pattern4 = pattern4[1:len(pattern4)]\n",
        "    pattern5 = pattern5[1:len(pattern5)]\n",
        "\n",
        "  return prediction_output\n",
        "\n",
        "def from_feature_to_info_dict(feature_list):\n",
        "  \n",
        "  featurnames = sorted(set(item for item in feature_list))\n",
        "  n_vocab_feature = len(set(feature_list))\n",
        "  \n",
        "  return featurnames,n_vocab_feature\n",
        "\n",
        "def create_csv_musical_content(output_song_info,num_song):\n",
        "  df = pd.DataFrame(columns=[\"note_name\", \"offset\", \"duration\", \"velocity\", \"tempo\"])\n",
        "\n",
        "  for el in output_song_info:\n",
        "    new_df = pd.DataFrame([[ el[0], el[1], el[2], el[3], el[4] ]], columns=[\"note_name\", \"offset\", \"duration\", \"velocity\", \"tempo\"])\n",
        "    df = df.append(new_df, ignore_index=True) \n",
        "  \n",
        "  df.to_csv(\"test_output\"+ str(num_song) +\".csv\")\n",
        "\n",
        "def generate(num_bra,ROOT_PATH_DATA,model):\n",
        "  print(\"--------- BRANO\" + str(num_bra) + \"--------------\")\n",
        "\n",
        "  network_input_notes,network_input_offsets,network_input_durations,network_input_velocities,network_input_tempos = load_test_sequences(ROOT_PATH_DATA)\n",
        "\n",
        "  notes,offsets,durations,velocities,tempos = load_features(ROOT_PATH_DATA)\n",
        "\n",
        "  notenames,n_vocab_notes = from_feature_to_info_dict(notes)\n",
        "  offsetnames,n_vocab_offsets = from_feature_to_info_dict(offsets)\n",
        "  durationnames,n_vocab_durations = from_feature_to_info_dict(durations)\n",
        "  velocitynames,n_vocab_velocities = from_feature_to_info_dict(velocities)\n",
        "  temponames,n_vocab_tempos = from_feature_to_info_dict(tempos)\n",
        "\n",
        "  #attraverso le predizioni del modello è possibile generare le note con le corrispettive durate e offsets\n",
        "\n",
        "  prediction_output = generate_music(\n",
        "  model, \n",
        "  network_input_notes,network_input_offsets,network_input_durations,network_input_velocities,network_input_tempos, \n",
        "  notenames, offsetnames, durationnames,velocitynames, temponames,\n",
        "  n_vocab_notes, n_vocab_offsets, n_vocab_durations,n_vocab_velocities,n_vocab_tempos\n",
        "  )\n",
        "\n",
        "  create_csv_musical_content(prediction_output,num_bra)\n",
        "\n",
        "def prepare_model(PATH_MODEL):\n",
        "  print (\"load model...\")\n",
        "\n",
        "  model = load_model_from_local(PATH_MODEL)\n",
        "  model.load_weights(\"weights-improvement-50-3.9211-bigger.hdf5\")\n",
        "\n",
        "  print (\"finish\")\n",
        "  return model\n",
        "\n",
        "#------- MAIN DI GENERAZIONE -------\n",
        "\n",
        "N_BRANI_DA_GENERARE = 10\n",
        "ROOT_PATH_DATA = \"d_prova_pickle\"\n",
        "#ROOT_PATH_DATA = \"dataset_pickle/dataset_pickle\"\n",
        "PATH_MODEL = \"model\"\n",
        "\n",
        "model = prepare_model(PATH_MODEL)\n",
        "\n",
        "\n",
        "for i in range(0,N_BRANI_DA_GENERARE):\n",
        "  generate(i,ROOT_PATH_DATA,model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}